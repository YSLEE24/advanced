# âœ… build_faiss_vectorstore_section_only.py

from bs4 import BeautifulSoup
from pathlib import Path
import pandas as pd
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.embeddings import HuggingFaceEmbeddings
from langchain.vectorstores import FAISS
from langchain.schema import Document
import os

def extract_and_save_faiss(base_dir="templates/contents", out_path="faiss_store/contents"):
    contentList = []  # ì „ì²´ ë¬¸ì„œ chunk ë‹´ì„ ë¦¬ìŠ¤íŠ¸

    # âœ… í…ìŠ¤íŠ¸ ë¶„í• ê¸°: 600ì ë‹¨ìœ„, 80ì ê²¹ì¹˜ê¸°
    splitter = RecursiveCharacterTextSplitter(
        chunk_size=600,
        chunk_overlap=80,
        separators=["\n\n", "\n", ".", " "],
    )

    # âœ… ëª¨ë“  HTML íŒŒì¼ ìˆœíšŒ
    for file_path in Path(base_dir).rglob("*.[hH][tT][mM][lL]"):  # ëŒ€ì†Œë¬¸ì ëª¨ë‘ ì¸ì‹
        with open(file_path, 'r', encoding='utf-8') as f:
            html_content = f.read()

        folder = os.path.basename(os.path.dirname(file_path))
        page = os.path.splitext(os.path.basename(file_path))[0]

        # âœ… BeautifulSoup íŒŒì‹±
        soup = BeautifulSoup(html_content, 'html.parser')

        # âœ… ëª¨ë“  section ì¶”ì¶œ
        sections = soup.select('[name="section"]')

        for section in sections:
            # âœ… title ì¶”ì¶œ (ì—†ì„ ìˆ˜ë„ ìˆìŒ)
            title_div = section.select_one('[name="content_title"]')
            title = title_div.get_text(strip=True) if title_div else ""

            # âœ… section ì „ì²´ í…ìŠ¤íŠ¸ ì¶”ì¶œ (title + ë³¸ë¬¸ í¬í•¨)
            section_text = section.get_text(separator="\n", strip=True)

            # âœ… chunk ë‹¨ìœ„ ë¶„ë¦¬
            chunks = splitter.split_text(section_text)

            for chunk in chunks:
                contentList.append([title, chunk, folder, page])

    # âœ… DataFrame ë³€í™˜
    df = pd.DataFrame(contentList, columns=["title", "content", "folder", "page"])

    # âœ… LangChain ë¬¸ì„œ ê°ì²´ ë³€í™˜
    documents = [
        Document(
            page_content=f"{row['title']}\n{row['page']}\n{row['content']}",
            metadata={
                "title": row['title'],
                "folder": row['folder'],
                "page": row['page'],
                "source": f"templates/contents/{row['folder']}/{row['page']}.html"
            }
        )
        for _, row in df.iterrows()
    ]

    # âœ… ì„ë² ë”© ëª¨ë¸ ë¡œë”©
    embedding_model = HuggingFaceEmbeddings(model_name="BM-K/KoSimCSE-roberta-multitask")

    # âœ… ë””ë²„ê¹…: ì „ì²´ ë¬¸ì„œ ìˆ˜ í™•ì¸
    print(f"\nğŸ“Œ ì „ì²´ ë¬¸ì„œ ê°œìˆ˜: {len(set(df['page']))}ê°œ, ì´ chunk ìˆ˜: {len(documents)}ê°œ")

    # âœ… ë²¡í„°ìŠ¤í† ì–´ ì €ì¥
    vectorstore = FAISS.from_documents(documents=documents, embedding=embedding_model)
    vectorstore.save_local(out_path)
    print(f"âœ… ì €ì¥ ì™„ë£Œ: {out_path}")

# âœ… ìŠ¤í¬ë¦½íŠ¸ ì§ì ‘ ì‹¤í–‰ ì‹œ
if __name__ == "__main__":
    extract_and_save_faiss()
